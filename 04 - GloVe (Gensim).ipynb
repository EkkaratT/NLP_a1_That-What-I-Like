{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe (Gensim)\n",
    "\n",
    "For looking at word vectors, we'll use **Gensim**. **Gensim** isn't really a deep learning package. It's a package for for word and text similarity modeling, which started with (LDA-style) topic models and grew into SVD and neural word representations. But its efficient and scalable, and quite widely used.   We gonna use **GloVe** embeddings, downloaded at [the Glove page](https://nlp.stanford.edu/projects/glove/). They're inside [this zip file](https://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = 'file/glove.6B.100d.txt'\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return the vectors\n",
    "model['coffee'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(path_to_file):\n",
    "    content = []  # Initialize content to an empty list to avoid returning None\n",
    "    try:\n",
    "        with open(path_to_file, 'r') as file:\n",
    "            content = file.readlines()  # Read all lines of the file into a list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {path_to_file} does not exist.\")  # File not found error\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  # Handle any other exceptions (e.g., permission issues)\n",
    "\n",
    "    return content  # Return content even if it's empty, but not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"file/word-test.v1.1.txt\"\n",
    "\n",
    "content = open_file(file_path)\n",
    "\n",
    "semantic = []\n",
    "syntatic = []\n",
    "\n",
    "current_test = semantic\n",
    "for sent in content:\n",
    "    if sent[0] == ':':\n",
    "        current_test = syntatic\n",
    "        continue\n",
    "    \n",
    "    current_test.append(sent.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "sem_total = len(semantic)\n",
    "sem_correct = 0\n",
    "\n",
    "for sent in semantic:\n",
    "    \n",
    "    sent = sent.lower()\n",
    "    words = sent.split(\" \")\n",
    "\n",
    "    try:\n",
    "        result = model.most_similar(positive=[words[1], words[2]], negative=[words[0]])[0][0]\n",
    "    except:\n",
    "        result = \"<UNK>\"\n",
    "\n",
    "    if result == words[3]:\n",
    "        sem_correct += 1\n",
    "        \n",
    "sem_accuracy = sem_correct / sem_total\n",
    "print(f\"Semantic accuracy: {sem_accuracy:2.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_total = len(syntatic)\n",
    "syn_correct = 0\n",
    "for sent in syntatic:\n",
    "\n",
    "    sent = sent.lower()\n",
    "    words = sent.split(\" \")\n",
    "\n",
    "    result = model.most_similar(positive=[words[1], words[2]], negative=[words[0]])[0][0]\n",
    "    \n",
    "    if result == words[3]:\n",
    "        syn_correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntatic accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "syn_accuracy = syn_correct / syn_total\n",
    "print(f\"Syntatic accuracy: {syn_accuracy:2.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"file/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "content = open_file(file_path)\n",
    "\n",
    "sim_data = []\n",
    "\n",
    "for sent in content:\n",
    "    sim_data.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "default_vector = np.zeros(model.vector_size)\n",
    "try:\n",
    "    result = model.get_vector('123123')\n",
    "except:\n",
    "    result = default_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_similarity(model, test_data):\n",
    "\n",
    "    words = test_data.split(\"\\t\")\n",
    "\n",
    "    default_vector = np.zeros(model.vector_size)\n",
    "    try:\n",
    "        embed0 = model.get_vector(words[0].strip())\n",
    "        embed1 = model.get_vector(words[1].strip())\n",
    "    except:\n",
    "        embed0 = default_vector\n",
    "        embed1 = default_vector\n",
    "        \n",
    "    similarity_model = embed1 @ embed0.T\n",
    "    similarity_provided = float(words[2].strip())\n",
    "\n",
    "    return similarity_provided, similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_scores = []\n",
    "model_scores = []\n",
    "for sent in sim_data:\n",
    "    ds_score, model_score = compute_similarity(model, sent)\n",
    "\n",
    "    ds_scores.append(ds_score)\n",
    "    model_scores.append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the dataset metrics and model scores is 0.53.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "corr = spearmanr(ds_scores, model_scores)[0]\n",
    "\n",
    "print(f\"Correlation between the dataset metrics and model scores is {corr:2.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barack', 0.937216579914093),\n",
       " ('bush', 0.9272855520248413),\n",
       " ('clinton', 0.896000325679779),\n",
       " ('mccain', 0.8875634074211121),\n",
       " ('gore', 0.8000320196151733),\n",
       " ('hillary', 0.7933663129806519),\n",
       " ('dole', 0.7851963639259338),\n",
       " ('rodham', 0.7518897652626038),\n",
       " ('romney', 0.7488929629325867),\n",
       " ('kerry', 0.7472624182701111)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cola', 0.8380194902420044),\n",
       " ('pepsi', 0.7717816233634949),\n",
       " ('coca', 0.7455084323883057),\n",
       " ('beer', 0.6947751045227051),\n",
       " ('pepsico', 0.6941383481025696),\n",
       " ('bottling', 0.6818284392356873),\n",
       " ('soda', 0.6482692360877991),\n",
       " ('drink', 0.6394657492637634),\n",
       " ('drinks', 0.6368611454963684),\n",
       " ('bottlers', 0.6348695755004883)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('coke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coconut', 0.7097253799438477),\n",
       " ('mango', 0.7054824829101562),\n",
       " ('bananas', 0.6887733936309814),\n",
       " ('potato', 0.6629636883735657),\n",
       " ('pineapple', 0.6534532308578491),\n",
       " ('fruit', 0.6519854068756104),\n",
       " ('peanut', 0.6420576572418213),\n",
       " ('pecan', 0.6349173188209534),\n",
       " ('cashew', 0.6294420957565308),\n",
       " ('papaya', 0.6246591210365295)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('languages', 0.8260655999183655),\n",
       " ('word', 0.7464082837104797),\n",
       " ('spoken', 0.7381494045257568),\n",
       " ('arabic', 0.7318817377090454),\n",
       " ('english', 0.7214903235435486),\n",
       " ('dialect', 0.6912704110145569),\n",
       " ('vocabulary', 0.6908208727836609),\n",
       " ('text', 0.685594916343689),\n",
       " ('translation', 0.6810674071311951),\n",
       " ('words', 0.6715823411941528)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plants', 0.8918153047561646),\n",
       " ('factory', 0.7068111896514893),\n",
       " ('farm', 0.6553632616996765),\n",
       " ('facility', 0.6538199782371521),\n",
       " ('production', 0.6336487531661987),\n",
       " ('produce', 0.6246358156204224),\n",
       " ('processing', 0.6155514121055603),\n",
       " ('fertilizer', 0.6091734170913696),\n",
       " ('waste', 0.6080261468887329),\n",
       " ('factories', 0.6015971302986145)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiple meanings....\n",
    "model.most_similar(\"plant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shunichi', 0.49618104100227356),\n",
       " ('ieronymos', 0.4736502170562744),\n",
       " ('pengrowth', 0.4668096601963043),\n",
       " ('höss', 0.4636845886707306),\n",
       " ('damaskinos', 0.46178486943244934),\n",
       " ('yadin', 0.4617375135421753),\n",
       " ('hundertwasser', 0.458895742893219),\n",
       " ('ncpa', 0.4577339291572571),\n",
       " ('maccormac', 0.45661094784736633),\n",
       " ('rothfeld', 0.4523947536945343)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative='banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "#woman + king - man\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tapas: 0.6232\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['italy', 'sushi'], negative=['japan'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We have talked about this in the last class.  Here we can conveniently use `distance` to find the cosine distance between two words. Note that distance = 1 - similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1201925277709961, 0.6231490671634674)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dog\"\n",
    "w2 = \"cat\"\n",
    "w3 = \"fruit\"\n",
    "w1_w2_dist = model.distance(w1, w2)\n",
    "w1_w3_dist = model.distance(w1, w3)\n",
    "\n",
    "#dog is much closer to cat then dog to fruit\n",
    "w1_w2_dist, w1_w3_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4540063142776489, 0.31988638639450073)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"happy\" # synonym 1\n",
    "w2 = \"cheerful\" # synonym 2\n",
    "w3 = \"sad\" # antonym\n",
    "w1_w2_dist = model.distance(w1, w2)\n",
    "w1_w3_dist = model.distance(w1, w3)\n",
    "\n",
    "#$w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\"!!\n",
    "#those similarlity does not handle antonym....\n",
    "w1_w2_dist, w1_w3_dist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "\n",
    "You guys....one very important thing is that NLP models are biased.....very bad...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nurse', 0.6614274978637695),\n",
      " ('employee', 0.6432636976242065),\n",
      " ('workers', 0.6231536865234375),\n",
      " ('migrant', 0.6021152138710022),\n",
      " ('immigrant', 0.5768847465515137),\n",
      " ('child', 0.5701467394828796),\n",
      " ('nurses', 0.5673795342445374),\n",
      " ('pregnant', 0.5660357475280762),\n",
      " ('nursing', 0.5648376941680908),\n",
      " ('teacher', 0.5609063506126404)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(model.most_similar(positive=['woman', 'worker'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(model.most_similar(positive=['man', 'worker'], negative=['woman']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(model.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'australian'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('japan', 'japanese', 'australia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('japan', 'sushi', 'italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('australia', 'beer', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('obama', 'clinton', 'reagan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('good', 'fantastic', 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('bird', 'fly', 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which word in the list does not belong\n",
    "print(model.doesnt_match(\"coke pepsi sprite water\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = ['coffee', 'tea', 'beer', 'wine', 'brandy', 'rum', 'champagne', 'water',\n",
    "        'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',\n",
    "        'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',\n",
    "        'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',\n",
    "        'france', 'germany', 'hungary', 'luxembourg', 'australia', 'fiji', 'china',\n",
    "        'homework', 'assignment', 'problem', 'exam', 'test', 'class',\n",
    "        'school', 'college', 'university', 'institute']\n",
    "\n",
    "word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "twodim = PCA().fit_transform(word_vectors)[:,:2]  #transform 100 to 2 dimensions\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "for word, (x,y) in zip(words, twodim):\n",
    "    plt.text(x+0.05, y+0.05, word)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
